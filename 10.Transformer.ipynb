{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ad8019",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Что такое Transformer\n",
    "\n",
    "* Архитектура нейронных сетей, представленная в статье *\"Attention Is All You Need\" (2017)*.\n",
    "* Создана для задач последовательной обработки: перевод, суммаризация, генерация.\n",
    "* Главное отличие: **полное отсутствие рекуррентных и сверточных слоёв**.\n",
    "* Основная идея: **Self-Attention**, позволяющая модели фокусироваться на значимых токенах.\n",
    "\n",
    "\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Transformer%2C_full_architecture.png/1280px-Transformer%2C_full_architecture.png)\n",
    "\n",
    "\n",
    "## Проблемы предыдущих архитектур\n",
    "\n",
    "### RNN / LSTM / GRU:\n",
    "\n",
    "* Последовательная обработка → низкая скорость.\n",
    "* Сложности с долгими зависимостями.\n",
    "* Взрыв/затухание градиентов.\n",
    "\n",
    "### CNN в NLP:\n",
    "\n",
    "* Ограниченный receptive field.\n",
    "* Много слоёв для дальних зависимостей.\n",
    "\n",
    "\n",
    "\n",
    "## Основа структуры Transformer\n",
    "\n",
    "Классический Transformer состоит из двух симметричных частей:\n",
    "\n",
    "* **Encoder** — извлекает представления входа.\n",
    "* **Decoder** — генерирует выход шаг за шагом.\n",
    "\n",
    "Каждый состоит из N одинаковых блоков.\n",
    "\n",
    "### Encoder block:\n",
    "\n",
    "1. Multi-Head Self-Attention\n",
    "2. Feed-Forward Network (FFN)\n",
    "3. Skip-connections + LayerNorm\n",
    "\n",
    "### Decoder block:\n",
    "\n",
    "1. Masked Multi-Head Self-Attention\n",
    "2. Encoder–Decoder Attention\n",
    "3. Feed-Forward Network\n",
    "4. Skip-connections + LayerNorm\n",
    "\n",
    "\n",
    "\n",
    "## Что такое Attention\n",
    "\n",
    "Attention — механизм, который решает: *какие токены важны для обработки текущего токена?*\n",
    "\n",
    "В self-attention каждый токен взаимодействует с каждым.\n",
    "\n",
    "Формально attention вычисляется так:\n",
    "\n",
    "\n",
    "$\\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}\\!\\left(\\frac{QK^{\\top}}{\\sqrt{d_k}}\\right) V$\n",
    "\n",
    "\n",
    "* **Q (Query)** — запрос.\n",
    "* **K (Key)** — ключ.\n",
    "* **V (Value)** — значение.\n",
    "* $d_k$ — размерность ключей.\n",
    "\n",
    "\n",
    "\n",
    "## Q, K, V \n",
    "\n",
    "Представим, что модель читает предложение:\n",
    "\n",
    "> \"The cat sat on the mat\"\n",
    "\n",
    "Для токена *\"cat\"* она формирует:\n",
    "\n",
    "* **Query** — что я ищу?\n",
    "* **Key** — чем я являюсь?\n",
    "* **Value** — какую информацию несу?\n",
    "\n",
    "Attention определяет, насколько каждый токен важен для *\"cat\"*.\n",
    "\n",
    "\n",
    "\n",
    "## Multi-Head Attention\n",
    "\n",
    "Вместо одного self-attention используется несколько:\n",
    "\n",
    "* Каждый head учится признавать разные типы зависимостей.\n",
    "* Пример: один head фокусируется на синтаксисе, другой — на согласовании чисел, третий — на семантике.\n",
    "\n",
    "$$\\mathrm{MultiHead}(Q, K, V) = \\mathrm{concat}( \\text{head}_1, \\ldots, \\text{head}_h ) \\, W_o$$\n",
    "\n",
    "* h — число heads.\n",
    "* Каждый head имеет свои $W_q$, $W_k$, $W_v$.\n",
    "\n",
    "\n",
    "\n",
    "## Почему Attention эффективнее RNN\n",
    "\n",
    "* Параллелизм: self-attention вычисляется для всех токенов одновременно.\n",
    "* Глобальные зависимости обрабатываются за 1 шаг.\n",
    "* Сложность $O(n^2)$, но без последовательных зависимостей.\n",
    "\n",
    "\n",
    "\n",
    "## Positional embedding\n",
    "\n",
    "Поскольку в Transformer нет рекуррентности, модель не знает порядок токенов.\n",
    "\n",
    "Решение: **positional encoding**.\n",
    "\n",
    "Два типа:\n",
    "\n",
    "1. **Sinusoidal (оригинальный)**:\n",
    "\n",
    "$$\n",
    "pos[2i] = sin(pos / 10000^{2i/d}) \n",
    "$$\n",
    "$$\n",
    "pos[2i+1] = cos(pos / 10000^{2i/d})\n",
    "$$\n",
    "\n",
    "2. **Learned** — обучаемые embedding.\n",
    "\n",
    "3. ...\n",
    "\n",
    "## Feed-Forward Block (FFN)\n",
    "\n",
    "В каждом энкодере и декодере после attention следует FFN:\n",
    "\n",
    "$$\\mathrm{FFN}(x) = \\max(0,\\, x W_{1} + b_{1})\\, W_{2} + b_{2}$$\n",
    "\n",
    "\n",
    "* Увеличивает размерность (d → 4d → d).\n",
    "* Применяется отдельно к каждому токену.\n",
    "* Добавляет нелинейность и улучшает представления.\n",
    "\n",
    "\n",
    "\n",
    "## Layer Normalization и Skip Connections\n",
    "\n",
    "### Skip connections:\n",
    "\n",
    "* Помогают при обучении глубоких моделей.\n",
    "* Борются с затуханием градиентов.\n",
    "\n",
    "### LayerNorm:\n",
    "\n",
    "* Нормализует активации каждого слоя.\n",
    "* Стабилизирует обучение.\n",
    "\n",
    "\n",
    "\n",
    "## Почему Transformer стал революцией\n",
    "\n",
    "* Резкий качества в NLP моделях.\n",
    "* Огромная скорость обучения.\n",
    "* Легче параллелить.\n",
    "* Отлично масштабируется (GPT, BERT, T5, LLaMA).\n",
    "* Универсальная архитектура для текста, изображений, аудио.\n",
    "\n",
    "\n",
    "\n",
    "## Эволюция Transformer\n",
    "\n",
    "* **2018** — BERT (энкодер).\n",
    "* **2018** — GPT (декодер).\n",
    "* **2020** — T5 (encoder–decoder).\n",
    "* **2021+** — Vision Transformer, Audio Transformer, Multimodal.\n",
    "* **2023+** — FlashAttention, Linear Attention.\n",
    "\n",
    "\n",
    "\n",
    "## Ограничения Transformer\n",
    "\n",
    "* Квадратичная сложность $O(n^2)$ по длине.\n",
    "* Большие требования к GPU.\n",
    "* Медленный инференс у больших моделей.\n",
    "\n",
    "Решения: те же FlashAttention, LLaMA-style оптимизации, Mixture-of-Experts.\n",
    "\n",
    "\n",
    "\n",
    "## Общая схема ванильного Transformer\n",
    "\n",
    "```\n",
    "Input → Embedding → Positional Encoding\n",
    " → Encoder (N слоёв)\n",
    " → Decoder (N слоёв)\n",
    " → Linear → Softmax → Output\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
