{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4460a01f",
   "metadata": {},
   "source": [
    "# RAG — Retrieval-Augmented Generation\n",
    "\n",
    "## Генерация с опорой на знания)\n",
    "\n",
    "Большие языковые модели:\n",
    "\n",
    "* не имеют доступа (не обучались на) приватных данных\n",
    "* имеют устаревшие знания\n",
    "* склонны к галлюцинациям\n",
    "\n",
    "Пример:\n",
    "\n",
    "> «Что написано во внутренней документации компании?»\n",
    "\n",
    "LLM **не имеет доступа** к этим данным.\n",
    "\n",
    "\n",
    "## Наивные решения (и почему они плохи)\n",
    "\n",
    "### 1. Дообучение (fine-tuning)\n",
    "\n",
    "* дорого\n",
    "* долго\n",
    "* сложно обновлять знания\n",
    "\n",
    "### 2. Просто вставить всё в prompt\n",
    "\n",
    "* ограничение по context window\n",
    "* дорого\n",
    "* плохо масштабируется\n",
    "\n",
    "\n",
    "## Идея RAG\n",
    "\n",
    "**Retrieval-Augmented Generation** =\n",
    "\n",
    "> LLM + внешний источник знаний\n",
    "\n",
    "Модель:\n",
    "\n",
    "1. **ищет** релевантные документы\n",
    "2. **читает** их\n",
    "3. **генерирует ответ**, опираясь на них\n",
    "\n",
    "## Классическая схема RAG\n",
    "\n",
    "1. Пользовательский запрос\n",
    "2. Поиск релевантных документов\n",
    "3. Формирование prompt с контекстом\n",
    "4. Генерация ответа LLM\n",
    "\n",
    "## Из чего состоит RAG-система\n",
    "\n",
    "### Основные компоненты:\n",
    "\n",
    "* **Документы** (PDF, Markdown, HTML, DB)\n",
    "* **Chunking** — разбиение текста\n",
    "* **Embeddings** — векторное представление\n",
    "* **Vector Store** — поиск по векторам\n",
    "* **LLM** — генерация ответа\n",
    "\n",
    "\n",
    "## Chunking — зачем и как\n",
    "\n",
    "Почему нельзя хранить документ целиком:\n",
    "\n",
    "* слишком длинный\n",
    "* плохо ищется\n",
    "\n",
    "Chunking:\n",
    "\n",
    "* 200–1000 токенов\n",
    "* часто с overlap (перекрытием)\n",
    "\n",
    "\n",
    "## Embeddings\n",
    "\n",
    "Embedding — это:\n",
    "\n",
    "* отображение текста → вектор\n",
    "* семантическая близость = близость векторов\n",
    "\n",
    "Используются для:\n",
    "\n",
    "* semantic search\n",
    "* similarity\n",
    "\n",
    "Популярные модели:\n",
    "\n",
    "* OpenAI text-embedding-3\n",
    "* bge\n",
    "* e5\n",
    "\n",
    "\n",
    "## Vector Store (векторная БД)\n",
    "\n",
    "Хранит:\n",
    "\n",
    "* embedding\n",
    "* текст chunk'а\n",
    "* метаданные\n",
    "\n",
    "Примеры:\n",
    "\n",
    "* FAISS\n",
    "* Qdrant\n",
    "* Milvus\n",
    "* Weaviate\n",
    "\n",
    "Решают задачу `kNN`. \n",
    "\n",
    "\n",
    "## Retriever\n",
    "\n",
    "Retriever = логика поиска:\n",
    "\n",
    "* embedding запроса\n",
    "* similarity search\n",
    "* фильтры по метаданным\n",
    "\n",
    "Варианты:\n",
    "\n",
    "* cosine similarity\n",
    "* dot product\n",
    "* hybrid (BM25 + vectors)\n",
    "\n",
    "## Формирование prompt\n",
    "\n",
    "Один из ключевых этапов!\n",
    "\n",
    "Пример:\n",
    "\n",
    "```\n",
    "Answer the question using only the context below.\n",
    "\n",
    "Context:\n",
    "- chunk 1\n",
    "- chunk 2\n",
    "\n",
    "Question:\n",
    "...\n",
    "```\n",
    "\n",
    "Плохой prompt -> галлюцинации\n",
    "\n",
    "## Генерация ответа\n",
    "\n",
    "LLM:\n",
    "\n",
    "* читает контекст\n",
    "* обобщает\n",
    "* отвечает\n",
    "\n",
    "\n",
    "\n",
    "## Минимальный RAG-пайплайн (псевдокод)\n",
    "\n",
    "```python\n",
    "query_emb = embed(query)\n",
    "docs = vector_db.search(query_emb, k=5)\n",
    "\n",
    "prompt = build_prompt(query, docs)\n",
    "answer = llm.generate(prompt)\n",
    "```\n",
    "\n",
    "Просто, концептуально, масштабируемо.\n",
    "\n",
    "\n",
    "## Где возникают проблемы\n",
    "\n",
    "Типичные ошибки:\n",
    "\n",
    "* плохой chunking\n",
    "* нерелевантный retrieval\n",
    "* слишком много контекста\n",
    "* слабые embeddings\n",
    "\n",
    "\n",
    "## Улучшения RAG\n",
    "\n",
    "* **Re-ranking** (cross-encoder)\n",
    "* **Multi-query retrieval**\n",
    "* **Hybrid search**\n",
    "* **Query rewriting**\n",
    "* **Context compression**\n",
    "\n",
    "\n",
    "## Advanced RAG\n",
    "\n",
    "* RAG + агенты\n",
    "* RAG + tools\n",
    "* RAG + SQL / API\n",
    "* Graph RAG\n",
    "* Self-RAG (проверка ответа)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
